{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9413e232",
   "metadata": {},
   "source": [
    "# 1. Build docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b25d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2e81e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  2.564MB\n",
      "Step 1/12 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-cpu-py36-ubuntu16.04\n",
      " ---> e77085e0f844\n",
      "Step 2/12 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> c6e213b7a95d\n",
      "Step 3/12 : COPY ./code /opt/ml/code\n",
      " ---> eee743023e35\n",
      "Step 4/12 : RUN mkdir -p /opt/ml/model &&     ls -l /opt/ml/code &&     pip install -r /opt/ml/code/requirements.txt\n",
      " ---> Running in 7dad89e3f0e9\n",
      "total 32\n",
      "drwxrwxr-x 2 root root  4096 Nov 29 14:41 __pycache__\n",
      "-rw-rw-r-- 1 root root  3226 Nov 29 14:41 deploy_ei.py\n",
      "-rw-rw-r-- 1 root root    77 Dec  2 06:44 requirements.txt\n",
      "-rw-rw-r-- 1 root root  1320 Nov 29 14:41 test.py\n",
      "-rw-rw-r-- 1 root root 13160 Dec  2 07:47 train_deploy.py\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/code/requirements.txt (line 1)) (4.56.0)\n",
      "Requirement already satisfied: requests==2.22.0 in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/code/requirements.txt (line 2)) (2.22.0)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.11.10-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Collecting transformers==2.3.0\n",
      "  Downloading transformers-2.3.0-py3-none-any.whl (447 kB)\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.11.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests==2.22.0->-r /opt/ml/code/requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests==2.22.0->-r /opt/ml/code/requirements.txt (line 2)) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests==2.22.0->-r /opt/ml/code/requirements.txt (line 2)) (1.25.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests==2.22.0->-r /opt/ml/code/requirements.txt (line 2)) (2.8)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from transformers==2.3.0->-r /opt/ml/code/requirements.txt (line 6)) (1.17.26)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from transformers==2.3.0->-r /opt/ml/code/requirements.txt (line 6)) (1.16.4)\n",
      "Collecting fsspec==2021.11.1\n",
      "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
      "Collecting aiohttp<=4\n",
      "  Downloading aiohttp-3.8.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Collecting aiobotocore~=2.0.1\n",
      "  Downloading aiobotocore-2.0.1.tar.gz (54 kB)\n",
      "Collecting botocore<1.22.9,>=1.22.8\n",
      "  Downloading botocore-1.22.8-py3-none-any.whl (8.1 MB)\n",
      "Collecting wrapt>=1.10.10\n",
      "  Downloading wrapt-1.13.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (78 kB)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.8.0-py3-none-any.whl (21 kB)\n",
      "Collecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.0.8-py3-none-any.whl (39 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (270 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (191 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.6/site-packages (from aiohttp<=4->s3fs->-r /opt/ml/code/requirements.txt (line 7)) (3.7.4.3)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (159 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from botocore<1.22.9,>=1.22.8->aiobotocore~=2.0.1->s3fs->-r /opt/ml/code/requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore<1.22.9,>=1.22.8->aiobotocore~=2.0.1->s3fs->-r /opt/ml/code/requirements.txt (line 7)) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.9,>=1.22.8->aiobotocore~=2.0.1->s3fs->-r /opt/ml/code/requirements.txt (line 7)) (1.15.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->-r /opt/ml/code/requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->-r /opt/ml/code/requirements.txt (line 5)) (7.1.2)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.3.0->-r /opt/ml/code/requirements.txt (line 6)) (0.3.4)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.20.18-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.17-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.16-py3-none-any.whl (131 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.20.15-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.14-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.13-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.12-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.11-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.10-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.9-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.8-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.7-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.6-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.5-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.4-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.3-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.2-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.1-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.20.0-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.19.12-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.19.11-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.19.10-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.19.9-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.19.8-py3-none-any.whl (131 kB)\n",
      "Building wheels for collected packages: aiobotocore, idna-ssl\n",
      "  Building wheel for aiobotocore (setup.py): started\n",
      "  Building wheel for aiobotocore (setup.py): finished with status 'done'\n",
      "  Created wheel for aiobotocore: filename=aiobotocore-2.0.1-py3-none-any.whl size=51978 sha256=4c2f739ed62a3c909d4db9ee780f87614168ccac2ecfa7bd78280396e35fba8a\n",
      "  Stored in directory: /root/.cache/pip/wheels/73/b7/3b/15481dc56d092eba140bebca5486d592b34b90f93b99c46d3b\n",
      "  Building wheel for idna-ssl (setup.py): started\n",
      "  Building wheel for idna-ssl (setup.py): finished with status 'done'\n",
      "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3160 sha256=ba08d80d26d4925a531db96c7b334fad43fe5c1c054b49438e9ab7d5cdf32f86\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "Successfully built aiobotocore idna-ssl\n",
      "Installing collected packages: multidict, frozenlist, yarl, idna-ssl, charset-normalizer, botocore, attrs, asynctest, async-timeout, aiosignal, wrapt, s3transfer, regex, aioitertools, aiohttp, sentencepiece, sacremoses, fsspec, boto3, aiobotocore, transformers, s3fs\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.26\n",
      "    Uninstalling botocore-1.20.26:\n",
      "      Successfully uninstalled botocore-1.20.26\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.4\n",
      "    Uninstalling s3transfer-0.3.4:\n",
      "      Successfully uninstalled s3transfer-0.3.4\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.26\n",
      "    Uninstalling boto3-1.17.26:\n",
      "      Successfully uninstalled boto3-1.17.26\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.19.26 requires botocore==1.20.26, but you have botocore 1.22.8 which is incompatible.\n",
      "awscli 1.19.26 requires s3transfer<0.4.0,>=0.3.0, but you have s3transfer 0.5.0 which is incompatible.\n",
      "\u001b[0mSuccessfully installed aiobotocore-2.0.1 aiohttp-3.8.1 aioitertools-0.8.0 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 attrs-21.2.0 boto3-1.19.8 botocore-1.22.8 charset-normalizer-2.0.8 frozenlist-1.2.0 fsspec-2021.11.1 idna-ssl-1.1.0 multidict-5.2.0 regex-2021.11.10 s3fs-2021.11.1 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 transformers-2.3.0 wrapt-1.13.3 yarl-1.7.2\n",
      "Removing intermediate container 7dad89e3f0e9\n",
      " ---> 405eab4db6f5\n",
      "Step 5/12 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 51207b6fd2ad\n",
      "Removing intermediate container 51207b6fd2ad\n",
      " ---> c20da8cf166d\n",
      "Step 6/12 : ENV SAGEMAKER_PROGRAM train_deploy.py\n",
      " ---> Running in 3f7f12110f74\n",
      "Removing intermediate container 3f7f12110f74\n",
      " ---> 1ad8a98d32ad\n",
      "Step 7/12 : ENV SM_HOSTS='[\"algo-1\",\"algo-2\"]'\n",
      " ---> Running in 0876e2da19f2\n",
      "Removing intermediate container 0876e2da19f2\n",
      " ---> c9ebee60ddfc\n",
      "Step 8/12 : ENV SM_CURRENT_HOST=algo-1\n",
      " ---> Running in 5370b4e20b4a\n",
      "Removing intermediate container 5370b4e20b4a\n",
      " ---> 6757716cceb7\n",
      "Step 9/12 : ENV SM_MODEL_DIR=/opt/ml/model\n",
      " ---> Running in 40e96e762897\n",
      "Removing intermediate container 40e96e762897\n",
      " ---> 7a86d13f9769\n",
      "Step 10/12 : ENV SM_CHANNEL_TRAINING=s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/data/input\n",
      " ---> Running in 6afed9c55028\n",
      "Removing intermediate container 6afed9c55028\n",
      " ---> ca95cf480d4f\n",
      "Step 11/12 : ENV SM_CHANNEL_TESTING=s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/data/input\n",
      " ---> Running in 8421bbde2636\n",
      "Removing intermediate container 8421bbde2636\n",
      " ---> 6a12c7787f36\n",
      "Step 12/12 : ENV SM_NUM_GPUS=0\n",
      " ---> Running in 8ac89d8b21f5\n",
      "Removing intermediate container 8ac89d8b21f5\n",
      " ---> 0059ae69d333\n",
      "Successfully built 0059ae69d333\n",
      "Successfully tagged grammer-classification-bert-base-uncased:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t grammer-classification-bert-base-uncased -f Dockerfile ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db74ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --name ivy-grammer-classification grammer-classification-bert-base-uncased:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4da40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82b62ea6",
   "metadata": {},
   "source": [
    "# 2. Push to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56476aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420737321821.dkr.ecr.us-east-1.amazonaws.com/grammer-classification-bert-base-uncased:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sts\")\n",
    "account = client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "algorithm_name = \"grammer-classification-bert-base-uncased\"\n",
    "\n",
    "ecr_image = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account, region, algorithm_name)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws ecr get-login-password | docker login xxxx -U AWS --password-stdin\n",
    "# !docker tag pytorch-bert-base-uncased:latest ECR_IMAGE \n",
    "# !docker push ECR_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30f4394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Login Succeeded\n",
      "The push refers to repository [420737321821.dkr.ecr.us-east-1.amazonaws.com/grammer-classification-bert-base-uncased]\n",
      "0bf23823ffca: Preparing\n",
      "0b6d4fed022e: Preparing\n",
      "6160e55345f6: Preparing\n",
      "b8897f99fee4: Preparing\n",
      "dc1b4f416d27: Preparing\n",
      "912a9194a89a: Preparing\n",
      "0bb6ba7c32f9: Preparing\n",
      "d6b6f976152c: Preparing\n",
      "bd9ea4625f76: Preparing\n",
      "31aed7f45c93: Preparing\n",
      "2dc64f428e8f: Preparing\n",
      "6225f83539e8: Preparing\n",
      "dbcf411e8bf0: Preparing\n",
      "5276d2b930fc: Preparing\n",
      "e6feec0db89a: Preparing\n",
      "697949baa658: Preparing\n",
      "935c56d8b3f9: Preparing\n",
      "31aed7f45c93: Waiting\n",
      "2dc64f428e8f: Waiting\n",
      "6225f83539e8: Waiting\n",
      "dbcf411e8bf0: Waiting\n",
      "5276d2b930fc: Waiting\n",
      "e6feec0db89a: Waiting\n",
      "697949baa658: Waiting\n",
      "935c56d8b3f9: Waiting\n",
      "912a9194a89a: Waiting\n",
      "0bb6ba7c32f9: Waiting\n",
      "d6b6f976152c: Waiting\n",
      "bd9ea4625f76: Waiting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "denied: User: arn:aws:sts::420737321821:assumed-role/CUSPFE-SageMaker-ML-Team-Execution-Role-Test/SageMaker is not authorized to perform: ecr:InitiateLayerUpload on resource: arn:aws:ecr:us-east-1:420737321821:repository/grammer-classification-bert-base-uncased because no identity-based policy allows the ecr:InitiateLayerUpload action\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\n# The name of our algorithm\\nalgorithm_name=grammer-classification-bert-base-uncased\\n\\naccount=$(aws sts get-caller-identity --query Account --output text)\\n\\n# Get the region defined in the current configuration (default to us-west-2 if none defined)\\nregion=$(aws configure get region)\\nregion=${region:-us-west-2}\\n\\nfullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\\n\\n# If the repository doesn\\'t exist in ECR, create it.\\n\\naws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\\n\\nif [ $? -ne 0 ]\\nthen\\n    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\\nfi\\n\\n# Get the login command from ECR and execute it directly\\n$(aws ecr get-login --region ${region} --no-include-email)\\n\\n# # Get the login command from ECR in order to pull down the SageMaker PyTorch image\\n# $(aws ecr get-login --registry-ids 520713654638 --region ${region} --no-include-email)\\n\\n# # Build the docker image locally with the image name and then push it to ECR\\n# # with the full name.\\n\\naws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\\n\\n# docker build  -t ${algorithm_name} . --build-arg REGION=${region}\\ndocker tag ${algorithm_name} ${fullname}\\n\\ndocker push ${fullname}\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-ae28c32ecd55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n# The name of our algorithm\\nalgorithm_name=grammer-classification-bert-base-uncased\\n\\naccount=$(aws sts get-caller-identity --query Account --output text)\\n\\n# Get the region defined in the current configuration (default to us-west-2 if none defined)\\nregion=$(aws configure get region)\\nregion=${region:-us-west-2}\\n\\nfullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\\n\\n# If the repository doesn\\'t exist in ECR, create it.\\n\\naws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\\n\\nif [ $? -ne 0 ]\\nthen\\n    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\\nfi\\n\\n# Get the login command from ECR and execute it directly\\n$(aws ecr get-login --region ${region} --no-include-email)\\n\\n# # Get the login command from ECR in order to pull down the SageMaker PyTorch image\\n# $(aws ecr get-login --registry-ids 520713654638 --region ${region} --no-include-email)\\n\\n# # Build the docker image locally with the image name and then push it to ECR\\n# # with the full name.\\n\\naws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\\n\\n# docker build  -t ${algorithm_name} . --build-arg REGION=${region}\\ndocker tag ${algorithm_name} ${fullname}\\n\\ndocker push ${fullname}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\n# The name of our algorithm\\nalgorithm_name=grammer-classification-bert-base-uncased\\n\\naccount=$(aws sts get-caller-identity --query Account --output text)\\n\\n# Get the region defined in the current configuration (default to us-west-2 if none defined)\\nregion=$(aws configure get region)\\nregion=${region:-us-west-2}\\n\\nfullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\\n\\n# If the repository doesn\\'t exist in ECR, create it.\\n\\naws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\\n\\nif [ $? -ne 0 ]\\nthen\\n    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\\nfi\\n\\n# Get the login command from ECR and execute it directly\\n$(aws ecr get-login --region ${region} --no-include-email)\\n\\n# # Get the login command from ECR in order to pull down the SageMaker PyTorch image\\n# $(aws ecr get-login --registry-ids 520713654638 --region ${region} --no-include-email)\\n\\n# # Build the docker image locally with the image name and then push it to ECR\\n# # with the full name.\\n\\naws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\\n\\n# docker build  -t ${algorithm_name} . --build-arg REGION=${region}\\ndocker tag ${algorithm_name} ${fullname}\\n\\ndocker push ${fullname}\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=grammer-classification-bert-base-uncased\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# # Get the login command from ECR in order to pull down the SageMaker PyTorch image\n",
    "# $(aws ecr get-login --registry-ids 520713654638 --region ${region} --no-include-email)\n",
    "\n",
    "# # Build the docker image locally with the image name and then push it to ECR\n",
    "# # with the full name.\n",
    "\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\n",
    "\n",
    "# docker build  -t ${algorithm_name} . --build-arg REGION=${region}\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab118290",
   "metadata": {},
   "source": [
    "# 3. Deploy to Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04456cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-420737321821\n",
      "arn:aws:iam::420737321821:role/CUSPFE-SageMaker-ML-Team-Execution-Role-Test\n",
      "s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/pytorch-training-2021-11-29-14-48-31-535/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/ivy-demo-pytorch-bert\"\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "model_data=\"s3://{}/{}/pytorch-training-2021-11-29-14-48-31-535/output/model.tar.gz\".format(bucket, prefix)\n",
    "\n",
    "print(bucket)\n",
    "print(role)\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e3986e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(sagemaker_session.upload_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f0b3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-29 14:55:18  405589243 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/pytorch-training-2021-11-29-14-48-31-535/output/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cedc518",
   "metadata": {},
   "source": [
    "## 3.1 Creating a model from training output (model artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accfd601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammer-classification-bert-base-uncased-model-20211202031053\n"
     ]
    }
   ],
   "source": [
    "model_name_prefix = \"{}-model\".format(algorithm_name)\n",
    "timestamp = time.strftime('-%Y%m%d%H%M%S', time.gmtime())\n",
    "model_name = model_name_prefix + timestamp\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b3f4922",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateModel operation: Using non-ECR image \"grammer-classification-bert-base-uncased\" without Vpc repository access mode is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c602946b73eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     PrimaryContainer = {\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m'Image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocker_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;34m'ModelDataUrl'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_artifacts_s3_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     }\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateModel operation: Using non-ECR image \"grammer-classification-bert-base-uncased\" without Vpc repository access mode is not supported."
     ]
    }
   ],
   "source": [
    "sagemaker_client = boto3.client(service_name='sagemaker')\n",
    "\n",
    "model_artifacts_s3_path = model_data\n",
    "docker_image = algorithm_name\n",
    "\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': docker_image,\n",
    "        'ModelDataUrl': model_artifacts_s3_path,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "713d3d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"grammer-classification-bert-base-uncased-model-2021-12-02-03-09-55\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe89bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700f538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9c677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445515d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b7850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea27fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e8ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3699c675",
   "metadata": {},
   "source": [
    "## 3.1. Create Pytorch endpoint with predefined the pytorch framework\n",
    "- it will create the inference model and endpoint configure automatically\n",
    "- it will use the awe prebuilt pytorch framework, we don't need to build our own docker imag, but need to prepare the entrypoint script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da18c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.pytorch import PyTorchModel\n",
    "# help(PyTorchModel)\n",
    "\n",
    "import sagemaker\n",
    "# help(sagemaker.model.FrameworkModel)\n",
    "# help(sagemaker.model.Model)\n",
    "\n",
    "# from sagemaker.estimator import Estimator\n",
    "# help(Estimator)\n",
    "\n",
    "# help(estimator.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33fcdecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert\n"
     ]
    }
   ],
   "source": [
    "WORK_DIRECTORY = \"/home/ec2-user/SageMaker/amazon-sagemaker-bert-pytorch/cola_public\"\n",
    "my_prefix=\"sagemaker/ivy-demo-pytorch-bert/data/input\"\n",
    "data_location = sagemaker_session.upload_data(WORK_DIRECTORY, bucket=bucket, key_prefix=my_prefix)\n",
    "print(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5d5bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move: s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/test.csv to s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/data/input/test.csv\n",
      "move: s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/train.csv to s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/data/input/train.csv\n",
      "                           PRE data/\n",
      "                           PRE pytorch-training-2021-11-29-14-48-31-535/\n",
      "                           PRE raw/\n",
      "                           PRE tokenized/\n",
      "2021-12-02 06:32:45       6570 README\n"
     ]
    }
   ],
   "source": [
    "!aws s3 mv s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/test.csv s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/data/input/test.csv \n",
    "!aws s3 mv s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/train.csv s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/data/input/train.csv \n",
    "!aws s3 ls s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70bbc27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateTrainingJob operation: TrainingImageConfig with TrainingRepositoryAccessMode set to VPC must be provided when using a training image from a private Docker registry. Please provideTrainingImageConfig and TrainingRepositoryAccessMode set to VPC when using a training image from a private Docker registry.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-3b6d7e7894ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# estimator.fit(\"s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/data/input/\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \"\"\"\n\u001b[1;32m   1467\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateTrainingJob operation: TrainingImageConfig with TrainingRepositoryAccessMode set to VPC must be provided when using a training image from a private Docker registry. Please provideTrainingImageConfig and TrainingRepositoryAccessMode set to VPC when using a training image from a private Docker registry."
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "\n",
    "instance_type = 'ml.m5.large'\n",
    "# accelerator_type = 'ml.eia2.xlarge'\n",
    "# instance_type = 'ml.t2.medium'\n",
    "hyperparameters = {\"epochs\": 1}\n",
    "\n",
    "estimator = Estimator(\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=instance_type,\n",
    "    image_uri=\"grammer-classification-bert-base-uncased:latest\",\n",
    "    model_uri=model_data,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "estimator.fit()\n",
    "# estimator.fit(\"s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/data/input/\")\n",
    "\n",
    "\n",
    "# estimator.fit(\"file:///tmp/pytorch-example/cifar-10-data\")\n",
    "endpoint_name = 'grammar-classification-{}-ep'.format(time.time()).replace('.', '').replace('_', '')\n",
    "print(endpoint_name)\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"local\", #instance_type,\n",
    "#     accelerator_type=accelerator_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c300a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar-classification-1638413436289433-ep\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0d2b96536838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#     accelerator_type=accelerator_type,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_model_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_sagemaker_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         production_variant = sagemaker.production_variant(\n\u001b[1;32m    766\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccelerator_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36m_create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mservices\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;31m#SageMaker.Client.add_tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \"\"\"\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mcontainer_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_container_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccelerator_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_base_name_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/pytorch/model.py\u001b[0m in \u001b[0;36mprepare_container_def\u001b[0;34m(self, instance_type, accelerator_type)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mdeploy_key_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_code_key_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeploy_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mms_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mdeploy_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mdeploy_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_framework_env_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/pytorch/model.py\u001b[0m in \u001b[0;36m_is_mms_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \"\"\"\n\u001b[1;32m    283\u001b[0m         \u001b[0mlowest_mms_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpackaging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LOWEST_MMS_VERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mframework_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpackaging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mframework_version\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlowest_mms_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/packaging/version.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# Validate the version and parse it into pieces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid version: '{version}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "import time\n",
    "\n",
    "# instance_type = 'ml.m5.large'\n",
    "# accelerator_type = 'ml.eia2.xlarge'\n",
    "instance_type = 'ml.t2.medium'\n",
    "\n",
    "endpoint_name = 'grammar-classification-{}-ep'.format(time.time()).replace('.', '').replace('_', '')\n",
    "print(endpoint_name)\n",
    "pytorch = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    entry_point='train_deploy.py',\n",
    "    source_dir='code',\n",
    "#     framework_version='1.3.1',\n",
    "#     py_version='py3',\n",
    "    image_uri=\"grammer-classification-bert-base-uncased:latest\",\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Function will exit before endpoint is finished creating\n",
    "predictor = pytorch.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"local\", #instance_type,\n",
    "#     accelerator_type=accelerator_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44c770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365d4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fda5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c009e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c1755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb441637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4411387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.estimator import Estimator\n",
    "# help(Estimator.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83c70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# hyperparameters = {\"epochs\": 1}\n",
    "hyperparameters={\n",
    "        \"epochs\": 1,\n",
    "        \"num_labels\": 2,\n",
    "        \"backend\": \"gloo\",\n",
    "        \"lr\":0.1\n",
    "    }\n",
    "\n",
    "instance_type = \"ml.m4.xlarge\"\n",
    "model_uri=\"s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/pytorch-training-2021-11-29-14-48-31-535/output/model.tar.gz\"\n",
    "estimator = Estimator(\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=instance_type,\n",
    "    image_name=ecr_image,\n",
    "    model_uri=model_uri,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "estimator.fit()\n",
    "\n",
    "predictor = estimator.deploy(1, instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452f9e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = get_image_uri(boto3.Session().region_name, 'image-classification')\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774708ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "960a9583",
   "metadata": {},
   "source": [
    "# 4. Test the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1c4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925eb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
