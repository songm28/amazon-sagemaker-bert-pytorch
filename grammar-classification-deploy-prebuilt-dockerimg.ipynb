{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f167ddd7",
   "metadata": {},
   "source": [
    "# Precondition: the model is uploaded in s3 by training job or manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data=\"s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/pytorch-training-2021-11-29-14-48-31-535/output/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f97702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-420737321821\n",
      "arn:aws:iam::420737321821:role/CUSPFE-SageMaker-ML-Team-Execution-Role-Test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/ivy-demo-pytorch-bert\"\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(bucket)\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c7bd1",
   "metadata": {},
   "source": [
    "# 1. Create Pytorch endpoint with predefined the pytorch framework\n",
    "- it will create the inference model and endpoint configure automatically\n",
    "- it will use the awe prebuilt pytorch framework, we don't need to build our own docker imag, but need to prepare the entrypoint script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35659e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# instance_type = 'ml.m5.large'\n",
    "# accelerator_type = 'ml.eia2.xlarge'\n",
    "instance_type = 'ml.t2.medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d6e4161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar-classification-16383498089475572-ep\n",
      "----------!"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "endpoint_name = 'grammar-classification-{}-ep'.format(time.time()).replace('.', '').replace('_', '')\n",
    "print(endpoint_name)\n",
    "pytorch = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    entry_point='train_deploy.py',\n",
    "    source_dir='code',\n",
    "    framework_version='1.3.1',\n",
    "    py_version='py3',\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Function will exit before endpoint is finished creating\n",
    "predictor = pytorch.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "#     accelerator_type=accelerator_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5affba73",
   "metadata": {},
   "source": [
    "# 2. Test the endpoint\n",
    "the code can run outside sagemaker, like lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5433c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sagemaker_runtime_client = boto3.Session().client(service_name='runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab852042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def predict_grammer_text(text):\n",
    "    response = sagemaker_runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        ContentType='application/json', \n",
    "        Body=json.dumps(text)\n",
    "    )\n",
    "    result = response['Body'].read()\n",
    "    result = json.loads(result)\n",
    "    print('Probabilities for all classes: ', result)\n",
    "    predicted_class = np.argmax(result)\n",
    "    if predicted_class == 0:\n",
    "        print('Grammer incorrect!')\n",
    "    else:\n",
    "        print('Grammer correct.')\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e9dca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for all classes:  [[0.6232306361198425, -0.5857623815536499]]\n",
      "Grammer incorrect!\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "s = \"I am a girl come from Chinese.\"\n",
    "x = predict_grammer_text(s)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86750836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for all classes:  [[-0.879428505897522, 1.862220287322998]]\n",
      "Grammer correct.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "s = \"I am a girl from China.\"\n",
    "x = predict_grammer_text(s)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ebd8d",
   "metadata": {},
   "source": [
    "# 3. Clean the endpoint\n",
    "<b>Please remember to clean the endpoint if it is just for practice</b><br/>\n",
    "the endpoint will create ec2 instance in the backend to serve the predict request. if we didn't clean the endpoint, the ec2 instance will keep running in the backend which will generate cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "751c21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'> None\n"
     ]
    }
   ],
   "source": [
    "print(predictor.endpoint_name)\n",
    "resp = sagemaker_session.delete_endpoint(endpoint_name=predictor.endpoint_name)\n",
    "print(type(resp), resp)\n",
    "\n",
    "resp = sagemaker_session.delete_endpoint_config(endpoint_config_name=predictor.endpoint_name)\n",
    "print(type(resp), resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22caad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'> None\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_model.name)\n",
    "resp = sagemaker_session.delete_model(model_name=pytorch_model.name)\n",
    "print(type(resp), resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
