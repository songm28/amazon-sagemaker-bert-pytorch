{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e70887e",
   "metadata": {},
   "source": [
    "# 1. Build docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8a3937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  951.3kB\n",
      "Step 1/6 : FROM public.ecr.aws/bitnami/pytorch:latest\n",
      "latest: Pulling from bitnami/pytorch\n",
      "\n",
      "\u001b[1B435fd20e: Pulling fs layer \n",
      "\u001b[1Bc2529f5d: Pulling fs layer \n",
      "\u001b[1B40739f4c: Pulling fs layer \n",
      "\u001b[1Bac48cf6b: Pulling fs layer \n",
      "\u001b[1B2f619d46: Pulling fs layer \n",
      "\u001b[1B4dcfee87: Pulling fs layer \n",
      "\u001b[1B1b0c50f4: Pulling fs layer \n",
      "\u001b[1B473f00af: Pulling fs layer \n",
      "\u001b[1B0d6fc61e: Pull complete 4.7MB/564.7MBB\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2KDownloading  440.7MB/564.7MB\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:9bc7b87b81fb1d5fe396261caecf6b95b61ff3cbbd4d4095ca197597f9769fe6\n",
      "Status: Downloaded newer image for public.ecr.aws/bitnami/pytorch:latest\n",
      " ---> 47335f066f16\n",
      "Step 2/6 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Running in 06e655fb0afc\n",
      "Removing intermediate container 06e655fb0afc\n",
      " ---> c884da36886b\n",
      "Step 3/6 : COPY ./code /opt/ml/code\n",
      " ---> 1a3a4c7ed0e9\n",
      "Step 4/6 : RUN ls -l /opt/ml/code &&     pip install -r /opt/ml/code/requirements.txt\n",
      " ---> Running in 3231cbfc064b\n",
      "total 32\n",
      "drwxrwxr-x 2 root root  4096 Nov 30 03:59 __pycache__\n",
      "-rw-rw-r-- 1 root root  3226 Nov 30 03:59 deploy_ei.py\n",
      "-rw-rw-r-- 1 root root    73 Nov 30 03:59 requirements.txt\n",
      "-rw-rw-r-- 1 root root  1320 Nov 30 03:59 test.py\n",
      "-rw-rw-r-- 1 root root 12690 Nov 30 03:59 train_deploy.py\n",
      "\u001b[91mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "\u001b[0mCollecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Collecting requests==2.22.0\n",
      "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Collecting transformers==2.3.0\n",
      "  Downloading transformers-2.3.0-py3-none-any.whl (447 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/bitnami/python/lib/python3.7/site-packages (from requests==2.22.0->-r /opt/ml/code/requirements.txt (line 2)) (2021.10.8)\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<2.9,>=2.5\n",
      "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied: numpy in /opt/bitnami/python/lib/python3.7/site-packages (from transformers==2.3.0->-r /opt/ml/code/requirements.txt (line 6)) (1.21.4)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.20.16-py3-none-any.whl (131 kB)\n",
      "Collecting click\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: six in /opt/bitnami/python/lib/python3.7/site-packages/six-1.16.0-py3.7.egg (from sacremoses->-r /opt/ml/code/requirements.txt (line 5)) (1.16.0)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.24.0,>=1.23.16\n",
      "  Downloading botocore-1.23.16-py3-none-any.whl (8.3 MB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/bitnami/python/lib/python3.7/site-packages/importlib_metadata-4.8.2-py3.7.egg (from click->sacremoses->-r /opt/ml/code/requirements.txt (line 5)) (4.8.2)\n",
      "Collecting python-dateutil<3.0.0,>=2.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/bitnami/python/lib/python3.7/site-packages/typing_extensions-3.10.0.2-py3.7.egg (from importlib-metadata->click->sacremoses->-r /opt/ml/code/requirements.txt (line 5)) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/bitnami/python/lib/python3.7/site-packages/zipp-3.6.0-py3.7.egg (from importlib-metadata->click->sacremoses->-r /opt/ml/code/requirements.txt (line 5)) (3.6.0)\n",
      "Installing collected packages: urllib3, python-dateutil, jmespath, botocore, tqdm, s3transfer, regex, joblib, idna, click, chardet, sentencepiece, sacremoses, requests, boto3, transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.7\n",
      "    Uninstalling urllib3-1.26.7:\n",
      "      Successfully uninstalled urllib3-1.26.7\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.26.0\n",
      "    Uninstalling requests-2.26.0:\n",
      "      Successfully uninstalled requests-2.26.0\n",
      "Successfully installed boto3-1.20.16 botocore-1.23.16 chardet-3.0.4 click-8.0.3 idna-2.8 jmespath-0.10.0 joblib-1.1.0 python-dateutil-2.8.2 regex-2021.11.10 requests-2.22.0 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 tqdm-4.62.3 transformers-2.3.0 urllib3-1.25.11\n",
      "Removing intermediate container 3231cbfc064b\n",
      " ---> e9d757c10730\n",
      "Step 5/6 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Running in 7820514bf9e9\n",
      "Removing intermediate container 7820514bf9e9\n",
      " ---> 8837aab55039\n",
      "Step 6/6 : ENV SAGEMAKER_PROGRAM train_deploy.py\n",
      " ---> Running in 605a9a37540e\n",
      "Removing intermediate container 605a9a37540e\n",
      " ---> 806995bf79dc\n",
      "Successfully built 806995bf79dc\n",
      "Successfully tagged pytorch-bert-base-uncased:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t pytorch-bert-base-uncased -f Dockerfile ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae3106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ff9d804",
   "metadata": {},
   "source": [
    "# 2. Push to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4496a36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833719260605.dkr.ecr.us-east-1.amazonaws.com/pytorch-bert-base-uncased:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sts\")\n",
    "account = client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "algorithm_name = \"pytorch-bert-base-uncased\"\n",
    "\n",
    "ecr_image = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account, region, algorithm_name)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eaccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws ecr get-login-password | docker login xxxx -U AWS --password-stdin\n",
    "# !docker tag pytorch-bert-base-uncased:latest ECR_IMAGE \n",
    "# !docker push ECR_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0c7940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [833719260605.dkr.ecr.us-east-1.amazonaws.com/pytorch-bert-base-uncased]\n",
      "5e1f5763557f: Preparing\n",
      "afd64b4c3656: Preparing\n",
      "8de3ac157a9f: Preparing\n",
      "cb4d32b6b8f3: Preparing\n",
      "761ec9808e93: Preparing\n",
      "30fa00a9fc02: Preparing\n",
      "b7c8cba4cc48: Preparing\n",
      "33c1b39847d7: Preparing\n",
      "61f63cc748f7: Preparing\n",
      "bacd2038ff01: Preparing\n",
      "5b2e78f7eb38: Preparing\n",
      "33c1b39847d7: Waiting\n",
      "61f63cc748f7: Waiting\n",
      "bacd2038ff01: Waiting\n",
      "5b2e78f7eb38: Waiting\n",
      "30fa00a9fc02: Waiting\n",
      "b7c8cba4cc48: Waiting\n",
      "afd64b4c3656: Pushed\n",
      "761ec9808e93: Pushed\n",
      "cb4d32b6b8f3: Pushed\n",
      "30fa00a9fc02: Pushed\n",
      "61f63cc748f7: Pushed\n",
      "5e1f5763557f: Pushed\n",
      "bacd2038ff01: Pushed\n",
      "5b2e78f7eb38: Pushed\n",
      "33c1b39847d7: Pushed\n",
      "8de3ac157a9f: Pushed\n",
      "b7c8cba4cc48: Pushed\n",
      "latest: digest: sha256:8483606034fe3486e88ce1184ac6209ad3c593a4309771d1836d0d0fa602dfaa size: 2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=pytorch-bert-base-uncased\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# # Get the login command from ECR in order to pull down the SageMaker PyTorch image\n",
    "# $(aws ecr get-login --registry-ids 520713654638 --region ${region} --no-include-email)\n",
    "\n",
    "# # Build the docker image locally with the image name and then push it to ECR\n",
    "# # with the full name.\n",
    "\n",
    "# docker build  -t ${algorithm_name} . --build-arg REGION=${region}\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14650a17",
   "metadata": {},
   "source": [
    "# 3. Deploy to Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54384c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Estimator in module sagemaker.estimator:\n",
      "\n",
      "class Estimator(EstimatorBase)\n",
      " |  A generic Estimator to train using any supplied algorithm.\n",
      " |  \n",
      " |  This class is designed for use with algorithms that don't have their own, custom class.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Estimator\n",
      " |      EstimatorBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, image_uri, role, instance_count=None, instance_type=None, volume_size=30, volume_kms_key=None, max_run=86400, input_mode='File', output_path=None, output_kms_key=None, base_job_name=None, sagemaker_session=None, hyperparameters=None, tags=None, subnets=None, security_group_ids=None, model_uri=None, model_channel_name='model', metric_definitions=None, encrypt_inter_container_traffic=False, use_spot_instances=False, max_wait=None, checkpoint_s3_uri=None, checkpoint_local_path=None, enable_network_isolation=False, rules=None, debugger_hook_config=None, tensorboard_output_config=None, enable_sagemaker_metrics=None, profiler_config=None, disable_profiler=False, environment=None, max_retry_attempts=None, **kwargs)\n",
      " |      Initialize an ``Estimator`` instance.\n",
      " |      \n",
      " |      Args:\n",
      " |          image_uri (str): The container image to use for training.\n",
      " |          role (str): An AWS IAM role (either name or full ARN). The Amazon\n",
      " |              SageMaker training jobs and APIs that create Amazon SageMaker\n",
      " |              endpoints use this role to access training data and model\n",
      " |              artifacts. After the endpoint is created, the inference code\n",
      " |              might use the IAM role, if it needs to access an AWS resource.\n",
      " |          instance_count (int): Number of Amazon EC2 instances to use\n",
      " |              for training.\n",
      " |          instance_type (str): Type of EC2 instance to use for training,\n",
      " |              for example, 'ml.c4.xlarge'.\n",
      " |          volume_size (int): Size in GB of the EBS volume to use for\n",
      " |              storing input data during training (default: 30). Must be large\n",
      " |              enough to store training data if File Mode is used (which is the\n",
      " |              default).\n",
      " |          volume_kms_key (str): Optional. KMS key ID for encrypting EBS\n",
      " |              volume attached to the training instance (default: None).\n",
      " |          max_run (int): Timeout in seconds for training (default: 24 *\n",
      " |              60 * 60). After this amount of time Amazon SageMaker terminates\n",
      " |              the job regardless of its current status.\n",
      " |          input_mode (str): The input mode that the algorithm supports\n",
      " |              (default: 'File'). Valid modes:\n",
      " |      \n",
      " |              * 'File' - Amazon SageMaker copies the training dataset from the\n",
      " |                S3 location to a local directory.\n",
      " |              * 'Pipe' - Amazon SageMaker streams data directly from S3 to the\n",
      " |                container via a Unix-named pipe.\n",
      " |      \n",
      " |              This argument can be overriden on a per-channel basis using\n",
      " |              ``sagemaker.inputs.TrainingInput.input_mode``.\n",
      " |          output_path (str): S3 location for saving the training result (model\n",
      " |              artifacts and output files). If not specified, results are\n",
      " |              stored to a default bucket. If the bucket with the specific name\n",
      " |              does not exist, the estimator creates the bucket during the\n",
      " |              :meth:`~sagemaker.estimator.EstimatorBase.fit` method execution.\n",
      " |          output_kms_key (str): Optional. KMS key ID for encrypting the\n",
      " |              training output (default: None).\n",
      " |          base_job_name (str): Prefix for training job name when the\n",
      " |              :meth:`~sagemaker.estimator.EstimatorBase.fit` method launches.\n",
      " |              If not specified, the estimator generates a default job name,\n",
      " |              based on the training image name and current timestamp.\n",
      " |          sagemaker_session (sagemaker.session.Session): Session object which\n",
      " |              manages interactions with Amazon SageMaker APIs and any other\n",
      " |              AWS services needed. If not specified, the estimator creates one\n",
      " |              using the default AWS configuration chain.\n",
      " |          hyperparameters (dict): Dictionary containing the hyperparameters to\n",
      " |              initialize this estimator with.\n",
      " |          tags (list[dict]): List of tags for labeling a training job. For\n",
      " |              more, see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n",
      " |          subnets (list[str]): List of subnet ids. If not specified training\n",
      " |              job will be created without VPC config.\n",
      " |          security_group_ids (list[str]): List of security group ids. If not\n",
      " |              specified training job will be created without VPC config.\n",
      " |          model_uri (str): URI where a pre-trained model is stored, either\n",
      " |              locally or in S3 (default: None). If specified, the estimator\n",
      " |              will create a channel pointing to the model so the training job\n",
      " |              can download it. This model can be a 'model.tar.gz' from a\n",
      " |              previous training job, or other artifacts coming from a\n",
      " |              different source.\n",
      " |      \n",
      " |              In local mode, this should point to the path in which the model\n",
      " |              is located and not the file itself, as local Docker containers\n",
      " |              will try to mount the URI as a volume.\n",
      " |      \n",
      " |              More information:\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-deserialization\n",
      " |          model_channel_name (str): Name of the channel where 'model_uri' will\n",
      " |              be downloaded (default: 'model').\n",
      " |          metric_definitions (list[dict]): A list of dictionaries that defines\n",
      " |              the metric(s) used to evaluate the training jobs. Each\n",
      " |              dictionary contains two keys: 'Name' for the name of the metric,\n",
      " |              and 'Regex' for the regular expression used to extract the\n",
      " |              metric from the logs. This should be defined only for jobs that\n",
      " |              don't use an Amazon algorithm.\n",
      " |          encrypt_inter_container_traffic (bool): Specifies whether traffic\n",
      " |              between training containers is encrypted for the training job\n",
      " |              (default: ``False``).\n",
      " |          use_spot_instances (bool): Specifies whether to use SageMaker\n",
      " |              Managed Spot instances for training. If enabled then the\n",
      " |              ``max_wait`` arg should also be set.\n",
      " |      \n",
      " |              More information:\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html\n",
      " |              (default: ``False``).\n",
      " |          max_wait (int): Timeout in seconds waiting for spot training\n",
      " |              instances (default: None). After this amount of time Amazon\n",
      " |              SageMaker will stop waiting for Spot instances to become\n",
      " |              available (default: ``None``).\n",
      " |          checkpoint_s3_uri (str): The S3 URI in which to persist checkpoints\n",
      " |              that the algorithm persists (if any) during training. (default:\n",
      " |              ``None``).\n",
      " |          checkpoint_local_path (str): The local path that the algorithm\n",
      " |              writes its checkpoints to. SageMaker will persist all files\n",
      " |              under this path to `checkpoint_s3_uri` continually during\n",
      " |              training. On job startup the reverse happens - data from the\n",
      " |              s3 location is downloaded to this path before the algorithm is\n",
      " |              started. If the path is unset then SageMaker assumes the\n",
      " |              checkpoints will be provided under `/opt/ml/checkpoints/`.\n",
      " |              (default: ``None``).\n",
      " |          enable_network_isolation (bool): Specifies whether container will\n",
      " |              run in network isolation mode (default: ``False``). Network\n",
      " |              isolation mode restricts the container access to outside networks\n",
      " |              (such as the Internet). The container does not make any inbound or\n",
      " |              outbound network calls. Also known as Internet-free mode.\n",
      " |          rules (list[:class:`~sagemaker.debugger.RuleBase`]): A list of\n",
      " |              :class:`~sagemaker.debugger.RuleBase` objects used to define\n",
      " |              SageMaker Debugger rules for real-time analysis\n",
      " |              (default: ``None``). For more information,\n",
      " |              see `Continuous analyses through rules\n",
      " |              <https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html\n",
      " |              #continuous-analyses-through-rules)>`_.\n",
      " |          debugger_hook_config (:class:`~sagemaker.debugger.DebuggerHookConfig` or bool):\n",
      " |              Configuration for how debugging information is emitted with\n",
      " |              SageMaker Debugger. If not specified, a default one is created using\n",
      " |              the estimator's ``output_path``, unless the region does not\n",
      " |              support SageMaker Debugger. To disable SageMaker Debugger,\n",
      " |              set this parameter to ``False``. For more information, see\n",
      " |              `Capture real-time debugging data during model training in Amazon SageMaker\n",
      " |              <https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html#\n",
      " |              capture-real-time-debugging-data-during-model-training-in-amazon-sagemaker>`_.\n",
      " |          tensorboard_output_config (:class:`~sagemaker.debugger.TensorBoardOutputConfig`):\n",
      " |              Configuration for customizing debugging visualization using TensorBoard\n",
      " |              (default: ``None``). For more information,\n",
      " |              see `Capture real time tensorboard data\n",
      " |              <https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_debugger.html#\n",
      " |              capture-real-time-tensorboard-data-from-the-debugging-hook>`_.\n",
      " |          enable_sagemaker_metrics (bool): enable SageMaker Metrics Time\n",
      " |              Series. For more information, see `AlgorithmSpecification API\n",
      " |              <https://docs.aws.amazon.com/sagemaker/latest/dg/\n",
      " |              API_AlgorithmSpecification.html#SageMaker-Type-AlgorithmSpecification-\n",
      " |              EnableSageMakerMetricsTimeSeries>`_.\n",
      " |              (default: ``None``).\n",
      " |          profiler_config (:class:`~sagemaker.debugger.ProfilerConfig`):\n",
      " |              Configuration for how SageMaker Debugger collects\n",
      " |              monitoring and profiling information from your training job.\n",
      " |              If not specified, Debugger will be configured with\n",
      " |              a default configuration and will save system and framework metrics\n",
      " |              the estimator's default ``output_path`` in Amazon S3.\n",
      " |              Use :class:`~sagemaker.debugger.ProfilerConfig` to configure this parameter.\n",
      " |              To disable SageMaker Debugger monitoring and profiling, set the\n",
      " |              ``disable_profiler`` parameter to ``True``.\n",
      " |          disable_profiler (bool): Specifies whether Debugger monitoring and profiling\n",
      " |              will be disabled (default: ``False``).\n",
      " |          environment (dict[str, str]) : Environment variables to be set for\n",
      " |              use during training job (default: ``None``)\n",
      " |          max_retry_attempts (int): The number of times to move a job to the STARTING status.\n",
      " |              You can specify between 1 and 30 attempts.\n",
      " |              If the value of attempts is greater than zero,\n",
      " |              the job is retried on InternalServerFailure\n",
      " |              the same number of attempts as the value.\n",
      " |              You can cap the total duration for your job by setting ``max_wait`` and ``max_run``\n",
      " |              (default: ``None``)\n",
      " |  \n",
      " |  create_model(self, role=None, image_uri=None, predictor_cls=None, vpc_config_override='VPC_CONFIG_DEFAULT', **kwargs)\n",
      " |      Create a model to deploy.\n",
      " |      \n",
      " |      The serializer and deserializer arguments are only used to define a\n",
      " |      default Predictor. They are ignored if an explicit predictor class is passed in.\n",
      " |      Other arguments are passed through to the Model class.\n",
      " |      \n",
      " |      Args:\n",
      " |          role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n",
      " |              which is also used during transform jobs. If not specified, the\n",
      " |              role from the Estimator will be used.\n",
      " |          image_uri (str): A Docker image URI to use for deploying the model.\n",
      " |              Defaults to the image used for training.\n",
      " |          predictor_cls (Predictor): The predictor class to use when\n",
      " |              deploying the model.\n",
      " |          vpc_config_override (dict[str, list[str]]): Optional override for VpcConfig set on\n",
      " |              the model.\n",
      " |              Default: use subnets and security groups from this Estimator.\n",
      " |              * 'Subnets' (list[str]): List of subnet ids.\n",
      " |              * 'SecurityGroupIds' (list[str]): List of security group ids.\n",
      " |          **kwargs: Additional parameters passed to :class:`~sagemaker.model.Model`\n",
      " |      \n",
      " |      .. tip::\n",
      " |      \n",
      " |          You can find additional parameters for using this method at\n",
      " |          :class:`~sagemaker.model.Model`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (sagemaker.model.Model) a Model ready for deployment.\n",
      " |  \n",
      " |  hyperparameters(self)\n",
      " |      Returns the hyperparameters as a dictionary to use for training.\n",
      " |      \n",
      " |      The fit() method, that does the model training, calls this method to\n",
      " |      find the hyperparameters you specified.\n",
      " |  \n",
      " |  set_hyperparameters(self, **kwargs)\n",
      " |      Placeholder docstring\n",
      " |  \n",
      " |  training_image_uri(self)\n",
      " |      Returns the docker image to use for training.\n",
      " |      \n",
      " |      The fit() method, that does the model training, calls this method to\n",
      " |      find the image to use for model training.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from EstimatorBase:\n",
      " |  \n",
      " |  compile_model(self, target_instance_family, input_shape, output_path, framework=None, framework_version=None, compile_max_run=900, tags=None, target_platform_os=None, target_platform_arch=None, target_platform_accelerator=None, compiler_options=None, **kwargs)\n",
      " |      Compile a Neo model using the input model.\n",
      " |      \n",
      " |      Args:\n",
      " |          target_instance_family (str): Identifies the device that you want to\n",
      " |              run your model after compilation, for example: ml_c5. For allowed\n",
      " |              strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |          input_shape (dict): Specifies the name and shape of the expected\n",
      " |              inputs for your trained model in json dictionary form, for\n",
      " |              example: {'data':[1,3,1024,1024]}, or {'var1': [1,1,28,28],\n",
      " |              'var2':[1,1,28,28]}\n",
      " |          output_path (str): Specifies where to store the compiled model\n",
      " |          framework (str): The framework that is used to train the original\n",
      " |              model. Allowed values: 'mxnet', 'tensorflow', 'keras', 'pytorch',\n",
      " |              'onnx', 'xgboost'\n",
      " |          framework_version (str): The version of the framework\n",
      " |          compile_max_run (int): Timeout in seconds for compilation (default:\n",
      " |              15 * 60). After this amount of time Amazon SageMaker Neo\n",
      " |              terminates the compilation job regardless of its current status.\n",
      " |          tags (list[dict]): List of tags for labeling a compilation job. For\n",
      " |              more, see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_Tag.html.\n",
      " |          target_platform_os (str): Target Platform OS, for example: 'LINUX'.\n",
      " |              For allowed strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |              It can be used instead of target_instance_family.\n",
      " |          target_platform_arch (str): Target Platform Architecture, for example: 'X86_64'.\n",
      " |              For allowed strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |              It can be used instead of target_instance_family.\n",
      " |          target_platform_accelerator (str, optional): Target Platform Accelerator,\n",
      " |              for example: 'NVIDIA'. For allowed strings see\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html.\n",
      " |              It can be used instead of target_instance_family.\n",
      " |          compiler_options (dict, optional): Additional parameters for compiler.\n",
      " |              Compiler Options are TargetPlatform / target_instance_family specific. See\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/API_OutputConfig.html for details.\n",
      " |          **kwargs: Passed to invocation of ``create_model()``.\n",
      " |              Implementations may customize ``create_model()`` to accept\n",
      " |              ``**kwargs`` to customize model creation during deploy. For\n",
      " |              more, see the implementation docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          sagemaker.model.Model: A SageMaker ``Model`` object. See\n",
      " |          :func:`~sagemaker.model.Model` for full details.\n",
      " |  \n",
      " |  delete_endpoint = func(*args, **kwargs)\n",
      " |  \n",
      " |  deploy(self, initial_instance_count, instance_type, serializer=None, deserializer=None, accelerator_type=None, endpoint_name=None, use_compiled_model=False, wait=True, model_name=None, kms_key=None, data_capture_config=None, tags=None, **kwargs)\n",
      " |      Deploy the trained model to an Amazon SageMaker endpoint.\n",
      " |      \n",
      " |       And then return ``sagemaker.Predictor`` object.\n",
      " |      \n",
      " |      More information:\n",
      " |      http://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html\n",
      " |      \n",
      " |      Args:\n",
      " |          initial_instance_count (int): Minimum number of EC2 instances to\n",
      " |              deploy to an endpoint for prediction.\n",
      " |          instance_type (str): Type of EC2 instance to deploy to an endpoint\n",
      " |              for prediction, for example, 'ml.c4.xlarge'.\n",
      " |          serializer (:class:`~sagemaker.serializers.BaseSerializer`): A\n",
      " |              serializer object, used to encode data for an inference endpoint\n",
      " |              (default: None). If ``serializer`` is not None, then\n",
      " |              ``serializer`` will override the default serializer. The\n",
      " |              default serializer is set by the ``predictor_cls``.\n",
      " |          deserializer (:class:`~sagemaker.deserializers.BaseDeserializer`): A\n",
      " |              deserializer object, used to decode data from an inference\n",
      " |              endpoint (default: None). If ``deserializer`` is not None, then\n",
      " |              ``deserializer`` will override the default deserializer. The\n",
      " |              default deserializer is set by the ``predictor_cls``.\n",
      " |          accelerator_type (str): Type of Elastic Inference accelerator to\n",
      " |              attach to an endpoint for model loading and inference, for\n",
      " |              example, 'ml.eia1.medium'. If not specified, no Elastic\n",
      " |              Inference accelerator will be attached to the endpoint. For more\n",
      " |              information:\n",
      " |              https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n",
      " |          endpoint_name (str): Name to use for creating an Amazon SageMaker\n",
      " |              endpoint. If not specified, the name of the training job is\n",
      " |              used.\n",
      " |          use_compiled_model (bool): Flag to select whether to use compiled\n",
      " |              (optimized) model. Default: False.\n",
      " |          wait (bool): Whether the call should wait until the deployment of\n",
      " |              model completes (default: True).\n",
      " |          model_name (str): Name to use for creating an Amazon SageMaker\n",
      " |              model. If not specified, the estimator generates a default job name\n",
      " |              based on the training image name and current timestamp.\n",
      " |          kms_key (str): The ARN of the KMS key that is used to encrypt the\n",
      " |              data on the storage volume attached to the instance hosting the\n",
      " |              endpoint.\n",
      " |          data_capture_config (sagemaker.model_monitor.DataCaptureConfig): Specifies\n",
      " |              configuration related to Endpoint data capture for use with\n",
      " |              Amazon SageMaker Model Monitoring. Default: None.\n",
      " |          tags(List[dict[str, str]]): Optional. The list of tags to attach to this specific\n",
      " |              endpoint. Example:\n",
      " |              >>> tags = [{'Key': 'tagname', 'Value': 'tagvalue'}]\n",
      " |              For more information about tags, see\n",
      " |              https://boto3.amazonaws.com/v1/documentation                /api/latest/reference/services/sagemaker.html#SageMaker.Client.add_tags\n",
      " |          **kwargs: Passed to invocation of ``create_model()``.\n",
      " |              Implementations may customize ``create_model()`` to accept\n",
      " |              ``**kwargs`` to customize model creation during deploy.\n",
      " |              For more, see the implementation docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          sagemaker.predictor.Predictor: A predictor that provides a ``predict()`` method,\n",
      " |              which can be used to send requests to the Amazon SageMaker\n",
      " |              endpoint and obtain inferences.\n",
      " |  \n",
      " |  disable_profiling(self)\n",
      " |      Update the current training job in progress to disable profiling.\n",
      " |      \n",
      " |      Debugger stops collecting the system and framework metrics\n",
      " |      and turns off the Debugger built-in monitoring and profiling rules.\n",
      " |  \n",
      " |  enable_default_profiling(self)\n",
      " |      Update training job to enable Debugger monitoring.\n",
      " |      \n",
      " |      This method enables Debugger monitoring with\n",
      " |      the default ``profiler_config`` parameter to collect system\n",
      " |      metrics and the default built-in ``profiler_report`` rule.\n",
      " |      Framework metrics won't be saved.\n",
      " |      To update training job to emit framework metrics, you can use\n",
      " |      :class:`~sagemaker.estimator.Estimator.update_profiler`\n",
      " |      method and specify the framework metrics you want to enable.\n",
      " |      \n",
      " |      This method is callable when the training job is in progress while\n",
      " |      Debugger monitoring is disabled.\n",
      " |  \n",
      " |  enable_network_isolation(self)\n",
      " |      Return True if this Estimator will need network isolation to run.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: Whether this Estimator needs network isolation or not.\n",
      " |  \n",
      " |  fit(self, inputs=None, wait=True, logs='All', job_name=None, experiment_config=None)\n",
      " |      Train a model using the input training dataset.\n",
      " |      \n",
      " |      The API calls the Amazon SageMaker CreateTrainingJob API to start\n",
      " |      model training. The API uses configuration you provided to create the\n",
      " |      estimator and the specified input training data to send the\n",
      " |      CreatingTrainingJob request to Amazon SageMaker.\n",
      " |      \n",
      " |      This is a synchronous operation. After the model training\n",
      " |      successfully completes, you can call the ``deploy()`` method to host the\n",
      " |      model using the Amazon SageMaker hosting services.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs (str or dict or sagemaker.inputs.TrainingInput or\n",
      " |              sagemaker.inputs.FileSystemInput): Information about the training data.\n",
      " |              This can be one of four types:\n",
      " |      \n",
      " |              * (str) the S3 location where training data is saved, or a file:// path in\n",
      " |                  local mode.\n",
      " |              * (dict[str, str] or dict[str, sagemaker.inputs.TrainingInput] or\n",
      " |                  dict[str, sagemaker.inputs.FileSystemInput]) If using multiple channels for\n",
      " |                  training data, you can specify a dict mapping channel names to strings or\n",
      " |                  :func:`~sagemaker.inputs.TrainingInput` objects or\n",
      " |                  :func:`~sagemaker.inputs.FileSystemInput` objects.\n",
      " |              * (sagemaker.inputs.TrainingInput) - channel configuration for S3 data sources\n",
      " |                  that can provide additional information as well as the path to the training\n",
      " |                  dataset.\n",
      " |                  See :func:`sagemaker.inputs.TrainingInput` for full details.\n",
      " |              * (sagemaker.inputs.FileSystemInput) - channel configuration for\n",
      " |                  a file system data source that can provide additional information as well as\n",
      " |                  the path to the training dataset.\n",
      " |      \n",
      " |          wait (bool): Whether the call should wait until the job completes (default: True).\n",
      " |          logs ([str]): A list of strings specifying which logs to print. Acceptable\n",
      " |              strings are \"All\", \"None\", \"Training\", or \"Rules\". To maintain backwards\n",
      " |              compatibility, boolean values are also accepted and converted to strings.\n",
      " |              Only meaningful when wait is True.\n",
      " |          job_name (str): Training job name. If not specified, the estimator generates\n",
      " |              a default job name based on the training image name and current timestamp.\n",
      " |          experiment_config (dict[str, str]): Experiment management configuration.\n",
      " |              Optionally, the dict can contain three keys:\n",
      " |              'ExperimentName', 'TrialName', and 'TrialComponentDisplayName'.\n",
      " |              The behavior of setting these keys is as follows:\n",
      " |              * If `ExperimentName` is supplied but `TrialName` is not a Trial will be\n",
      " |              automatically created and the job's Trial Component associated with the Trial.\n",
      " |              * If `TrialName` is supplied and the Trial already exists the job's Trial Component\n",
      " |              will be associated with the Trial.\n",
      " |              * If both `ExperimentName` and `TrialName` are not supplied the trial component\n",
      " |              will be unassociated.\n",
      " |              * `TrialComponentDisplayName` is used for display in Studio.\n",
      " |  \n",
      " |  get_vpc_config(self, vpc_config_override='VPC_CONFIG_DEFAULT')\n",
      " |      Returns VpcConfig dict either from this Estimator's subnets and security groups.\n",
      " |      \n",
      " |      Or else validate and return an optional override value.\n",
      " |      \n",
      " |      Args:\n",
      " |          vpc_config_override:\n",
      " |  \n",
      " |  latest_job_debugger_artifacts_path(self)\n",
      " |      Gets the path to the DebuggerHookConfig output artifacts.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: An S3 path to the output artifacts.\n",
      " |  \n",
      " |  latest_job_profiler_artifacts_path(self)\n",
      " |      Gets the path to the profiling output artifacts.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: An S3 path to the output artifacts.\n",
      " |  \n",
      " |  latest_job_tensorboard_artifacts_path(self)\n",
      " |      Gets the path to the TensorBoardOutputConfig output artifacts.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: An S3 path to the output artifacts.\n",
      " |  \n",
      " |  logs(self)\n",
      " |      Display the logs for Estimator's training job.\n",
      " |      \n",
      " |      If the output is a tty or a Jupyter cell, it will be color-coded based\n",
      " |      on which instance the log entry is from.\n",
      " |  \n",
      " |  prepare_workflow_for_training(self, job_name=None)\n",
      " |      Calls _prepare_for_training. Used when setting up a workflow.\n",
      " |      \n",
      " |      Args:\n",
      " |          job_name (str): Name of the training job to be created. If not\n",
      " |              specified, one is generated, using the base name given to the\n",
      " |              constructor if applicable.\n",
      " |  \n",
      " |  register(self, content_types, response_types, inference_instances, transform_instances, image_uri=None, model_package_name=None, model_package_group_name=None, model_metrics=None, metadata_properties=None, marketplace_cert=False, approval_status=None, description=None, compile_model_family=None, model_name=None, **kwargs)\n",
      " |      Creates a model package for creating SageMaker models or listing on Marketplace.\n",
      " |      \n",
      " |      Args:\n",
      " |          content_types (list): The supported MIME types for the input data.\n",
      " |          response_types (list): The supported MIME types for the output data.\n",
      " |          inference_instances (list): A list of the instance types that are used to\n",
      " |              generate inferences in real-time.\n",
      " |          transform_instances (list): A list of the instance types on which a transformation\n",
      " |              job can be run or on which an endpoint can be deployed.\n",
      " |          image_uri (str): The container image uri for Model Package, if not specified,\n",
      " |              Estimator's training container image will be used (default: None).\n",
      " |          model_package_name (str): Model Package name, exclusive to `model_package_group_name`,\n",
      " |              using `model_package_name` makes the Model Package un-versioned (default: None).\n",
      " |          model_package_group_name (str): Model Package Group name, exclusive to\n",
      " |              `model_package_name`, using `model_package_group_name` makes the Model Package\n",
      " |              versioned (default: None).\n",
      " |          model_metrics (ModelMetrics): ModelMetrics object (default: None).\n",
      " |          metadata_properties (MetadataProperties): MetadataProperties (default: None).\n",
      " |          marketplace_cert (bool): A boolean value indicating if the Model Package is certified\n",
      " |              for AWS Marketplace (default: False).\n",
      " |          approval_status (str): Model Approval Status, values can be \"Approved\", \"Rejected\",\n",
      " |              or \"PendingManualApproval\" (default: \"PendingManualApproval\").\n",
      " |          description (str): Model Package description (default: None).\n",
      " |          compile_model_family (str): Instance family for compiled model, if specified, a compiled\n",
      " |              model will be used (default: None).\n",
      " |          model_name (str): User defined model name (default: None).\n",
      " |          **kwargs: Passed to invocation of ``create_model()``. Implementations may customize\n",
      " |              ``create_model()`` to accept ``**kwargs`` to customize model creation during\n",
      " |              deploy. For more, see the implementation docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: A string of SageMaker Model Package ARN.\n",
      " |  \n",
      " |  transformer(self, instance_count, instance_type, strategy=None, assemble_with=None, output_path=None, output_kms_key=None, accept=None, env=None, max_concurrent_transforms=None, max_payload=None, tags=None, role=None, volume_kms_key=None, vpc_config_override='VPC_CONFIG_DEFAULT', enable_network_isolation=None, model_name=None)\n",
      " |      Return a ``Transformer`` that uses a SageMaker Model based on the training job.\n",
      " |      \n",
      " |      It reuses the SageMaker Session and base job name used by\n",
      " |      the Estimator.\n",
      " |      \n",
      " |      Args:\n",
      " |          instance_count (int): Number of EC2 instances to use.\n",
      " |          instance_type (str): Type of EC2 instance to use, for example,\n",
      " |              'ml.c4.xlarge'.\n",
      " |          strategy (str): The strategy used to decide how to batch records in\n",
      " |              a single request (default: None). Valid values: 'MultiRecord'\n",
      " |              and 'SingleRecord'.\n",
      " |          assemble_with (str): How the output is assembled (default: None).\n",
      " |              Valid values: 'Line' or 'None'.\n",
      " |          output_path (str): S3 location for saving the transform result. If\n",
      " |              not specified, results are stored to a default bucket.\n",
      " |          output_kms_key (str): Optional. KMS key ID for encrypting the\n",
      " |              transform output (default: None).\n",
      " |          accept (str): The accept header passed by the client to\n",
      " |              the inference endpoint. If it is supported by the endpoint,\n",
      " |              it will be the format of the batch transform output.\n",
      " |          env (dict): Environment variables to be set for use during the\n",
      " |              transform job (default: None).\n",
      " |          max_concurrent_transforms (int): The maximum number of HTTP requests\n",
      " |              to be made to each individual transform container at one time.\n",
      " |          max_payload (int): Maximum size of the payload in a single HTTP\n",
      " |              request to the container in MB.\n",
      " |          tags (list[dict]): List of tags for labeling a transform job. If\n",
      " |              none specified, then the tags used for the training job are used\n",
      " |              for the transform job.\n",
      " |          role (str): The ``ExecutionRoleArn`` IAM Role ARN for the ``Model``,\n",
      " |              which is also used during transform jobs. If not specified, the\n",
      " |              role from the Estimator will be used.\n",
      " |          volume_kms_key (str): Optional. KMS key ID for encrypting the volume\n",
      " |              attached to the ML compute instance (default: None).\n",
      " |          vpc_config_override (dict[str, list[str]]): Optional override for the\n",
      " |              VpcConfig set on the model.\n",
      " |              Default: use subnets and security groups from this Estimator.\n",
      " |      \n",
      " |              * 'Subnets' (list[str]): List of subnet ids.\n",
      " |              * 'SecurityGroupIds' (list[str]): List of security group ids.\n",
      " |      \n",
      " |          enable_network_isolation (bool): Specifies whether container will\n",
      " |              run in network isolation mode. Network isolation mode restricts\n",
      " |              the container access to outside networks (such as the internet).\n",
      " |              The container does not make any inbound or outbound network\n",
      " |              calls. If True, a channel named \"code\" will be created for any\n",
      " |              user entry script for inference. Also known as Internet-free mode.\n",
      " |              If not specified, this setting is taken from the estimator's\n",
      " |              current configuration.\n",
      " |          model_name (str): Name to use for creating an Amazon SageMaker\n",
      " |              model. If not specified, the estimator generates a default job name\n",
      " |              based on the training image name and current timestamp.\n",
      " |  \n",
      " |  update_profiler(self, rules=None, system_monitor_interval_millis=None, s3_output_path=None, framework_profile_params=None, disable_framework_metrics=False)\n",
      " |      Update training jobs to enable profiling.\n",
      " |      \n",
      " |      This method updates the ``profiler_config`` parameter\n",
      " |      and initiates Debugger built-in rules for profiling.\n",
      " |      \n",
      " |      Args:\n",
      " |          rules (list[:class:`~sagemaker.debugger.ProfilerRule`]): A list of\n",
      " |              :class:`~sagemaker.debugger.ProfilerRule` objects to define\n",
      " |              rules for continuous analysis with SageMaker Debugger. Currently, you can\n",
      " |              only add new profiler rules during the training job. (default: ``None``)\n",
      " |          s3_output_path (str): The location in S3 to store the output. If profiler is enabled\n",
      " |              once, s3_output_path cannot be changed. (default: ``None``)\n",
      " |          system_monitor_interval_millis (int): How often profiling system metrics are\n",
      " |              collected; Unit: Milliseconds (default: ``None``)\n",
      " |          framework_profile_params (:class:`~sagemaker.debugger.FrameworkProfile`):\n",
      " |              A parameter object for framework metrics profiling. Configure it using\n",
      " |              the :class:`~sagemaker.debugger.FrameworkProfile` class.\n",
      " |              To use the default framework profile parameters, pass ``FrameworkProfile()``.\n",
      " |              For more information about the default values,\n",
      " |              see :class:`~sagemaker.debugger.FrameworkProfile`. (default: ``None``)\n",
      " |          disable_framework_metrics (bool): Specify whether to disable all the framework metrics.\n",
      " |              This won't update system metrics and the Debugger built-in rules for monitoring.\n",
      " |              To stop both monitoring and profiling,\n",
      " |              use the :class:`~sagemaker.estimator.Estimator.desable_profiling`\n",
      " |              method. (default: ``False``)\n",
      " |      \n",
      " |      .. attention::\n",
      " |      \n",
      " |          Updating the profiling configuration for TensorFlow dataloader profiling\n",
      " |          is currently not available. If you started a TensorFlow training job only with\n",
      " |          monitoring and want to enable profiling while the training job is running,\n",
      " |          the dataloader profiling cannot be updated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from EstimatorBase:\n",
      " |  \n",
      " |  attach(training_job_name, sagemaker_session=None, model_channel_name='model') from abc.ABCMeta\n",
      " |      Attach to an existing training job.\n",
      " |      \n",
      " |      Create an Estimator bound to an existing training job, each subclass\n",
      " |      is responsible to implement\n",
      " |      ``_prepare_init_params_from_job_description()`` as this method delegates\n",
      " |      the actual conversion of a training job description to the arguments\n",
      " |      that the class constructor expects. After attaching, if the training job\n",
      " |      has a Complete status, it can be ``deploy()`` ed to create a SageMaker\n",
      " |      Endpoint and return a ``Predictor``.\n",
      " |      \n",
      " |      If the training job is in progress, attach will block until the training job\n",
      " |      completes, but logs of the training job will not display. To see the logs\n",
      " |      content, please call ``logs()``\n",
      " |      \n",
      " |      Examples:\n",
      " |          >>> my_estimator.fit(wait=False)\n",
      " |          >>> training_job_name = my_estimator.latest_training_job.name\n",
      " |          Later on:\n",
      " |          >>> attached_estimator = Estimator.attach(training_job_name)\n",
      " |          >>> attached_estimator.logs()\n",
      " |          >>> attached_estimator.deploy()\n",
      " |      \n",
      " |      Args:\n",
      " |          training_job_name (str): The name of the training job to attach to.\n",
      " |          sagemaker_session (sagemaker.session.Session): Session object which\n",
      " |              manages interactions with Amazon SageMaker APIs and any other\n",
      " |              AWS services needed. If not specified, the estimator creates one\n",
      " |              using the default AWS configuration chain.\n",
      " |          model_channel_name (str): Name of the channel where pre-trained\n",
      " |              model data will be downloaded (default: 'model'). If no channel\n",
      " |              with the same name exists in the training job, this option will\n",
      " |              be ignored.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Instance of the calling ``Estimator`` Class with the attached\n",
      " |          training job.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from EstimatorBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  model_data\n",
      " |      str: The model location in S3. Only set if Estimator has been ``fit()``.\n",
      " |  \n",
      " |  training_job_analytics\n",
      " |      Return a ``TrainingJobAnalytics`` object for the current training job.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "# help(Estimator.fit)\n",
    "help(Estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ed6287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::833719260605:role/ivy-sagemaker-role\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6712825",
   "metadata": {},
   "source": [
    "## 3.1 Put the pretrained model in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796b7a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.3.0\n",
      "  Downloading transformers-2.3.0-py3-none-any.whl (447 kB)\n",
      "\u001b[K     || 447 kB 23.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.3.0) (4.61.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     || 895 kB 70.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.3.0) (2021.4.4)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.3.0) (1.20.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.3.0) (2.26.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     || 1.2 MB 67.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.3.0) (1.19.5)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->transformers==2.3.0) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->transformers==2.3.0) (1.23.4)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->transformers==2.3.0) (0.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.24.0,>=1.23.4->boto3->transformers==2.3.0) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.24.0,>=1.23.4->boto3->transformers==2.3.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.4->boto3->transformers==2.3.0) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==2.3.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==2.3.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==2.3.0) (2021.10.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers==2.3.0) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers==2.3.0) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from click->sacremoses->transformers==2.3.0) (4.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->click->sacremoses->transformers==2.3.0) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->click->sacremoses->transformers==2.3.0) (3.6.0)\n",
      "Installing collected packages: sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.46 sentencepiece-0.1.96 transformers-2.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c72f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_model_name=\"bert-base-uncased\"\n",
    "# from transformers import pipeline\n",
    "# bert_model = pipeline(\"bert-base-uncased\")\n",
    "# bert_model.save_pretrained(\"./model\")\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "bert_model = BertForSequenceClassification.from_pretrained(my_model_name)\n",
    "bert_model.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "710daf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertForSequenceClassification\n",
    "# help(BertForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a1da78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "pytorch_model.bin\n",
      "total 32\n",
      "drwxrwxr-x 6 ec2-user ec2-user  4096 Nov 30 04:32 amazon-sagemaker-bert-pytorch\n",
      "drwxrwxr-x 4 ec2-user ec2-user  4096 Nov 29 08:42 docker_test_folder\n",
      "drwx------ 2 root     root     16384 Nov 29 03:17 lost+found\n",
      "drwxrwxr-x 6 ec2-user ec2-user  4096 Nov 29 08:41 sagemaker_train_demo\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  1140 Nov 30 04:00 Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "!cd model && tar czvf ../model.tar.gz *\n",
    "!cd ../ && ls -l\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22cf27b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 396112\n",
      "-rw-rw-r-- 1 ec2-user ec2-user     22068 Nov 30 04:13 bert-sm-python-SDK.ipynb\n",
      "drwxrwxr-x 4 ec2-user ec2-user      4096 Nov 30 04:18 code\n",
      "-rw-rw-r-- 1 ec2-user ec2-user       309 Nov 30 03:59 CODE_OF_CONDUCT.md\n",
      "-rw-rw-r-- 1 ec2-user ec2-user    255330 Nov 30 03:59 cola_public_1.1.zip\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      3306 Nov 30 03:59 CONTRIBUTING.md\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      1660 Nov 30 03:59 Dockerfile\n",
      "-rw-rw-r-- 1 ec2-user ec2-user       927 Nov 30 03:59 LICENSE\n",
      "drwxrwxr-x 2 ec2-user ec2-user      4096 Nov 30 04:31 model\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 405254398 Nov 30 04:33 model.tar.gz\n",
      "-rw-rw-r-- 1 ec2-user ec2-user     43678 Nov 30 04:33 pytorch-docker-deploy.ipynb\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      4957 Nov 30 03:59 README.md\n"
     ]
    }
   ],
   "source": [
    "!cd /home/ec2-user/SageMaker/amazon-sagemaker-bert-pytorch && ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "682623d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-833719260605/sagemaker/pytorch-bert-base-uncased/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"sagemaker/pytorch-bert-base-uncased\"\n",
    "\n",
    "fObj = open(\"model.tar.gz\", \"rb\")\n",
    "key = os.path.join(prefix, \"model.tar.gz\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(key).upload_fileobj(fObj)\n",
    "\n",
    "model_s3_link = \"s3://{}\".format(os.path.join(bucket, key))\n",
    "print(model_s3_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de096aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateTrainingJob operation: 1 validation error detected: Value 'ml.t2.medium' at 'resourceConfig.instanceType' failed to satisfy constraint: Member must satisfy enum value set: [ml.p2.xlarge, ml.m5.4xlarge, ml.m4.16xlarge, ml.p4d.24xlarge, ml.c5n.xlarge, ml.p3.16xlarge, ml.m5.large, ml.p2.16xlarge, ml.c4.2xlarge, ml.c5.2xlarge, ml.c4.4xlarge, ml.c5.4xlarge, ml.c5n.18xlarge, ml.g4dn.xlarge, ml.g4dn.12xlarge, ml.c4.8xlarge, ml.g4dn.2xlarge, ml.c5.9xlarge, ml.g4dn.4xlarge, ml.c5.xlarge, ml.g4dn.16xlarge, ml.c4.xlarge, ml.g4dn.8xlarge, ml.c5n.2xlarge, ml.c5n.4xlarge, ml.c5.18xlarge, ml.p3dn.24xlarge, ml.p3.2xlarge, ml.m5.xlarge, ml.m4.10xlarge, ml.c5n.9xlarge, ml.m5.12xlarge, ml.m4.xlarge, ml.m5.24xlarge, ml.m4.2xlarge, ml.p2.8xlarge, ml.m5.2xlarge, ml.p3.8xlarge, ml.m4.4xlarge]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-34945ecdfa32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \"\"\"\n\u001b[1;32m   1467\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateTrainingJob operation: 1 validation error detected: Value 'ml.t2.medium' at 'resourceConfig.instanceType' failed to satisfy constraint: Member must satisfy enum value set: [ml.p2.xlarge, ml.m5.4xlarge, ml.m4.16xlarge, ml.p4d.24xlarge, ml.c5n.xlarge, ml.p3.16xlarge, ml.m5.large, ml.p2.16xlarge, ml.c4.2xlarge, ml.c5.2xlarge, ml.c4.4xlarge, ml.c5.4xlarge, ml.c5n.18xlarge, ml.g4dn.xlarge, ml.g4dn.12xlarge, ml.c4.8xlarge, ml.g4dn.2xlarge, ml.c5.9xlarge, ml.g4dn.4xlarge, ml.c5.xlarge, ml.g4dn.16xlarge, ml.c4.xlarge, ml.g4dn.8xlarge, ml.c5n.2xlarge, ml.c5n.4xlarge, ml.c5.18xlarge, ml.p3dn.24xlarge, ml.p3.2xlarge, ml.m5.xlarge, ml.m4.10xlarge, ml.c5n.9xlarge, ml.m5.12xlarge, ml.m4.xlarge, ml.m5.24xlarge, ml.m4.2xlarge, ml.p2.8xlarge, ml.m5.2xlarge, ml.p3.8xlarge, ml.m4.4xlarge]"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# hyperparameters = {\"epochs\": 1}\n",
    "hyperparameters={\n",
    "        \"epochs\": 1,\n",
    "        \"num_labels\": 2,\n",
    "        \"backend\": \"gloo\",\n",
    "        \"lr\":0.1\n",
    "    }\n",
    "\n",
    "instance_type = \"ml.t2.medium\" #\"ml.m4.xlarge\"\n",
    "# model_uri=\"s3://sagemaker-us-east-1-420737321821/sagemaker/ivy-demo-pytorch-bert/pytorch-training-2021-11-29-14-48-31-535/output/model.tar.gz\"\n",
    "model_uri=model_s3_link\n",
    "estimator = Estimator(\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=instance_type,\n",
    "    image_uri=ecr_image,\n",
    "    model_uri=model_uri,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "estimator.fit()\n",
    "\n",
    "predictor = estimator.deploy(1, instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e5c535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:1\n"
     ]
    }
   ],
   "source": [
    "# import boto3\n",
    "# from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "# training_image = get_image_uri(boto3.Session().region_name, 'image-classification')\n",
    "# print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbed68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bbe1c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833719260605.dkr.ecr.us-east-1.amazonaws.com/pytorch-bert-base-uncased:latest\n"
     ]
    }
   ],
   "source": [
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a9c9622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.96 \u001b[0m\n",
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.97 \u001b[0m\u001b[1mWelcome to the Bitnami pytorch container\u001b[0m\n",
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.98 \u001b[0mSubscribe to project updates by watching \u001b[1mhttps://github.com/bitnami/bitnami-docker-pytorch\u001b[0m\n",
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.98 \u001b[0mSubmit issues and feature requests at \u001b[1mhttps://github.com/bitnami/bitnami-docker-pytorch/issues\u001b[0m\n",
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.98 \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!docker run pytorch-bert-base-uncased:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d4eb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                              COMMAND                  CREATED          STATUS                      PORTS     NAMES\n",
      "e7ab6cd208d1   pytorch-bert-base-uncased:latest   \"/opt/bitnami/script\"   20 seconds ago   Exited (0) 18 seconds ago             sad_goldstine\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf12f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.96 \u001b[0m\n",
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.97 \u001b[0m\u001b[1mWelcome to the Bitnami pytorch container\u001b[0m\n",
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.98 \u001b[0mSubscribe to project updates by watching \u001b[1mhttps://github.com/bitnami/bitnami-docker-pytorch\u001b[0m\n",
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.98 \u001b[0mSubmit issues and feature requests at \u001b[1mhttps://github.com/bitnami/bitnami-docker-pytorch/issues\u001b[0m\n",
      "\u001b[38;5;6m \u001b[38;5;5m04:44:54.98 \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!docker logs sad_goldstine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ef05871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309d668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "174d29fe",
   "metadata": {},
   "source": [
    "# 4. Test the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b5dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec24d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e09508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff363244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is ahead of 'origin/master' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   bert-sm-python-SDK.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t\u001b[31m.ipynb_checkpoints/Dockerfile-checkpoint\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/pytorch-docker-deploy-checkpoint.ipynb\u001b[m\n",
      "\t\u001b[31mcode/.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31mmodel.tar.gz\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6da22e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username for 'https://github.com/songm28/amazon-sagemaker-bert-pytorch.git': ^C\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dcd0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown option: -h\n",
      "usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n",
      "           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n",
      "           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n",
      "           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n",
      "           <command> [<args>]\n"
     ]
    }
   ],
   "source": [
    "!git -h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
